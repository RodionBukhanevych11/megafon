{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('contest_train.csv')\n",
    "test_df =pd.read_csv('contest_test.csv')\n",
    "print(test_df.shape)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_num = []\n",
    "for c in [c for c in train_df.columns[2:]]:\n",
    "    typ = train_df[c].dtype\n",
    "    uniq = len(np.unique(train_df[c]))\n",
    "    if uniq>=100: count_num.append(c)\n",
    "\n",
    "print('Number of numerical features:', len(count_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 = train_df[train_df[\"TARGET\"] == 0]\n",
    "df_class_1 = train_df[train_df[\"TARGET\"] == 1]\n",
    "df_class_2 = train_df[train_df[\"TARGET\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_class_2_over = df_class_2.sample(count_class_0, replace=True)\n",
    "\n",
    "train_df = pd.concat([df_class_0, df_class_1_over, df_class_2_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns[2:]:\n",
    "    fig, axs = plt.subplots(ncols=2)\n",
    "    sns.boxplot(x=train_df[col],ax=axs[0])\n",
    "    sns.boxplot(x=test_df[col],ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "abscorr=get_top_abs_correlations(train_df.iloc[:,2:], 700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df=abscorr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df=correlation_df[correlation_df[0]>=0.65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff8_9_10_4=train_df.groupby(['FEATURE_9','FEATURE_10','FEATURE_4'])['FEATURE_8'].agg([('FEATURE_8', 'mean')]).to_dict()\n",
    "coeff8_9_10_4=list(coeff8_9_10_4.values())\n",
    "dict_coeff8_9_10_4 = {}\n",
    "for d in coeff8_9:\n",
    "    dict_coeff8_9_10_4.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_number in [150,100,90,80,70,60,50,45,40,35,32,31,30,23,22,11,9,7,6,5,4,3,2,1]:\n",
    "    print(\"CN\",col_number)\n",
    "    col=test_df.iloc[:,1:].columns\n",
    "    low_categorical_list=[]\n",
    "    for c in col:\n",
    "        if len(test_df.iloc[:,1:][c].unique())<=col_number:\n",
    "            if not test_df.iloc[:,1:][c].isna().sum()>0:\n",
    "                low_categorical_list.append(c)\n",
    "    print(low_categorical_list)\n",
    "    for remove_col in high_nans_list:\n",
    "        if remove_col in low_categorical_list:\n",
    "                low_categorical_list.remove(remove_col)\n",
    "                print('remove',remove_col)\n",
    "    print(\"CN\",col_number,\"LEN\",len(low_categorical_list))\n",
    "    cat_list=list(test_df[low_categorical_list].apply(tuple, axis=1))\n",
    "    for column in high_nans_list:\n",
    "        coeff=test_df.groupby(low_categorical_list)[column].agg(lambda x: scipy.stats.mode(x)[0]).to_dict()\n",
    "        test_df[column] = test_df[column].fillna(pd.Series(cat_list).map(coeff))\n",
    "        print('NA',column,test_df[column].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "\n",
    "train_df[count_num] = mms.fit_transform(train_df[count_num])\n",
    "test_df[count_num] = mms.fit_transform(test_df[count_num])\n",
    "alldf_target=all_df['TARGET']\n",
    "all_df=all_df.drop(['TARGET'],axis=1)\n",
    "scaler = StandardScaler()\n",
    "for high_cat in standscale_list:\n",
    "    all_df[[high_cat]]=scaler.fit_transform(all_df[[high_cat]])\n",
    "standart_columns=[]\n",
    "\n",
    "for column in all_df.columns:\n",
    "    if all_df[column].describe()['std']>1:\n",
    "        standart_columns.append(column)\n",
    "for column in standart_columns:\n",
    "    all_df[column]=scaler.fit_transform(all_df[[column]])\n",
    "Y_train=train_df['TARGET']\n",
    "X_train=all_df[:24416]\n",
    "X_test=all_df[24416:]\n",
    "print(Y_train.shape,X_train.shape,X_test.shape)\n",
    "X_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"GradientBoostingClassifier\",\"SVC\",\"RandomForestClassifier\",\"ExtraTreesClassifier\",'KNeighborsClassifier',\"LogisticRegression\"]})\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")\n",
    "GBC = GradientBoostingClassifier()\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [300],\n",
    "              'learning_rate': [0.01],\n",
    "              'max_depth': [8],\n",
    "              'min_samples_leaf': [150],\n",
    "              'max_features': [0.1] \n",
    "              }\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"f1_macro\", n_jobs= 4, verbose = 1)\n",
    "gsGBC.fit(X_train,y_train)\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "GB_fit = gsGBC.fit(X_train, y_train)\n",
    "prediction = pd.Series(GB_fit.predict(X_test), name=\"Predicted\")\n",
    "results = pd.concat([ss['ID'],prediction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}